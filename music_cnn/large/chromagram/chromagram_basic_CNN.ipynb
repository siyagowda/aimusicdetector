{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e2a677-50de-4dc3-bd8e-81cc7cdd6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@imabhi1216/fine-tuning-a-pre-trained-resnet-18-model-for-image-classification-on-custom-dataset-with-pytorch-02df12e83c2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ea1fe4-52ef-4403-9e3e-d29221ce3f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85019ff-7e24-4d26-b8e3-dc15ca22aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf7ce45-40ae-420c-8ed9-8205ce733db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Load the pre-trained ResNet-18 model\n",
    "    model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "\n",
    "    # Modify the last layer of the model\n",
    "    num_classes = 2 # number of classes in dataset\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993bbd8e-5a49-444b-9113-ec87ffa5c9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 37297\n",
      "Validation set size: 7991\n",
      "Test set size: 7995\n"
     ]
    }
   ],
   "source": [
    "# Directory paths for the segments and lyrics\n",
    "ai_segments_path = \"/vol/bitbucket/sg2121/fypdataset/dataset_large2/normal_data/ai_segments\"\n",
    "human_segments_path = \"/vol/bitbucket/sg2121/fypdataset/dataset_large2/normal_data/human\"\n",
    "ai_chr_path = \"/vol/bitbucket/sg2121/fypdataset/dataset_large2/features/ai/Chromagram\"\n",
    "human_chr_path = \"/vol/bitbucket/sg2121/fypdataset/dataset_large2/features/human/Chromagram\"\n",
    "\n",
    "ai_aug_segments_path = \"/vol/bitbucket/sg2121/fypdataset/dataset_large2/normal_data/augmented_ai\"\n",
    "ai_aug_chr_path = \"/vol/bitbucket/sg2121/fypdataset/dataset_large2/features/ai_aug/Chromagram\"\n",
    "\n",
    "# Helper function to read file paths from a text file\n",
    "def read_file_paths(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        return [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Read all file paths from the text files\n",
    "train_files = read_file_paths('/vol/bitbucket/sg2121/fyp/aimusicdetector/train_test_split/bitbucket/augmented/train_files_w_aug.txt')\n",
    "val_files = read_file_paths('/vol/bitbucket/sg2121/fyp/aimusicdetector/train_test_split/bitbucket/augmented/val_files_w_aug.txt')\n",
    "test_files = read_file_paths('/vol/bitbucket/sg2121/fyp/aimusicdetector/train_test_split/bitbucket/augmented/test_files_w_aug.txt')\n",
    "\n",
    "\n",
    "# Function to convert segment file path to lyric file path\n",
    "def convert_to_chr_path(file_path, is_ai):\n",
    "    if is_ai:\n",
    "        if file_path.startswith(ai_segments_path):\n",
    "            base_chr_path = ai_chr_path\n",
    "        elif file_path.startswith(ai_aug_segments_path):\n",
    "            base_chr_path = ai_aug_chr_path\n",
    "        else:\n",
    "            return\n",
    "    else:\n",
    "        if file_path.startswith(human_segments_path):\n",
    "            base_chr_path = human_chr_path\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    # Convert filename to chromagram filename\n",
    "    file_name = os.path.basename(file_path).replace('.mp3', '-Chromagram.png')\n",
    "    return os.path.join(base_chr_path, file_name)\n",
    "\n",
    "\n",
    "# Process the file lists and create tuples of (lyric_path, label)\n",
    "def process_file_paths(file_paths, is_ai):\n",
    "    return [(convert_to_chr_path(file_path, is_ai), 0 if is_ai else 1) for file_path in file_paths]\n",
    "\n",
    "# Convert all file paths from the train, validation, and test sets\n",
    "ai_train_files = process_file_paths(train_files, is_ai=True)\n",
    "human_train_files = process_file_paths(train_files, is_ai=False)\n",
    "\n",
    "ai_val_files = process_file_paths(val_files, is_ai=True)\n",
    "human_val_files = process_file_paths(val_files, is_ai=False)\n",
    "\n",
    "ai_test_files = process_file_paths(test_files, is_ai=True)\n",
    "human_test_files = process_file_paths(test_files, is_ai=False)\n",
    "\n",
    "def clean(paths):\n",
    "    return [(p, l) for p, l in paths if p is not None]\n",
    "\n",
    "train_files_combined = clean(ai_train_files) + clean(human_train_files)\n",
    "val_files_combined = clean(ai_val_files) + clean(human_val_files)\n",
    "test_files_combined = clean(ai_test_files) + clean(human_test_files)\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(train_files_combined)\n",
    "random.shuffle(val_files_combined)\n",
    "random.shuffle(test_files_combined)\n",
    "\n",
    "# Check the splits\n",
    "print(f\"Training set size: {len(train_files_combined)}\")\n",
    "print(f\"Validation set size: {len(val_files_combined)}\")\n",
    "print(f\"Test set size: {len(test_files_combined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694aa3d8-3fd9-4268-8664-0c36ffb8d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class ChromagramDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data[idx]\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        filename = os.path.basename(path)\n",
    "        return image, label, filename\n",
    "        \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e897ebf9-9a1c-4e00-b124-3467a46b31b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 37297 samples\n",
      "Val set: 7991 samples\n",
      "Test set: 7995 samples\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = ChromagramDataset(train_files_combined, transform=transform)\n",
    "val_dataset = ChromagramDataset(val_files_combined, transform=transform)\n",
    "test_dataset = ChromagramDataset(test_files_combined, transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Confirm sizes\n",
    "print(f\"Train set: {len(train_dataset)} samples\")\n",
    "print(f\"Val set: {len(val_dataset)} samples\")\n",
    "print(f\"Test set: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860831a5-b6b9-4b45-90a5-1c1ab10bbb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Determine whether to use GPU or CPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        # Initialise running loss and correct predictions count for training\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over the training data loader\n",
    "        for inputs, labels, filenames in train_loader:\n",
    "            # Move inputs and labels to the device (GPU or CPU)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Reset the gradients to zero before the backward pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: compute the model output\n",
    "            outputs = model(inputs)\n",
    "            # Get the predicted class (with the highest score)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            # Compute the loss between the predictions and actual labels\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass: compute gradients\n",
    "            loss.backward()\n",
    "            # Perform the optimization step to update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the running loss and the number of correct predictions\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Compute average training loss and accuracy for this epoch\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = running_corrects.float() / len(train_loader.dataset)\n",
    "\n",
    "        # Set the model to evaluation mode for validation\n",
    "        model.eval()\n",
    "        # Initialize running loss and correct predictions count for validation\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Disable gradient computation for validation\n",
    "        with torch.no_grad():\n",
    "            # Iterate over the validation data loader\n",
    "            for inputs, labels, filenames in val_loader:\n",
    "                # Move inputs and labels to the device (GPU or CPU)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass: compute the model output\n",
    "                outputs = model(inputs)\n",
    "                # Get the predicted class (with the highest score)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                # Compute the loss between the predictions and actual labels\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Accumulate the running loss and the number of correct predictions\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Compute average validation loss and accuracy for this epoch\n",
    "        val_loss = running_loss / len(val_loader.dataset)\n",
    "        val_acc = running_corrects.float() / len(val_loader.dataset)\n",
    "\n",
    "        # Print the results for the current epoch\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce2227b-acb5-4de9-8c9f-3638b7fe08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "lr = 0.001\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr, momentum=0.9)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c4cfc7-ccbb-427e-adc7-af1f4fd7e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters from search\n",
    "lr = 0.001\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-06)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df85e827-8692-42e7-9773-44f12a8096b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], train loss: 0.3376, train acc: 0.8453, val loss: 0.2694, val acc: 0.8800\n",
      "Epoch [2/5], train loss: 0.2308, train acc: 0.9008, val loss: 0.2644, val acc: 0.8846\n",
      "Epoch [3/5], train loss: 0.1724, train acc: 0.9278, val loss: 0.2809, val acc: 0.8867\n",
      "Epoch [4/5], train loss: 0.1227, train acc: 0.9507, val loss: 0.3245, val acc: 0.8821\n",
      "Epoch [5/5], train loss: 0.0860, train acc: 0.9665, val loss: 0.3814, val acc: 0.8859\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa2aded-43e3-457f-843e-4f1439615d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, hyperparams=None):\n",
    "    log_file = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/chromagram/training_large_logfile.txt\"\n",
    "\n",
    "    model.eval()\n",
    "    correct_pred = {classname: 0 for classname in ['ai', 'human']}\n",
    "    total_pred = {classname: 0 for classname in ['ai', 'human']}\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, filenames in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            for label, prediction in zip(labels, preds):\n",
    "                classname = 'ai' if label.item() == 0 else 'human'\n",
    "                if label == prediction:\n",
    "                    correct_pred[classname] += 1\n",
    "                total_pred[classname] += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    avg_inference_time = (end_time - start_time) / len(test_loader.dataset)\n",
    "\n",
    "    accuracy_per_class = {\n",
    "        classname: correct_pred[classname] / total_pred[classname]\n",
    "        if total_pred[classname] > 0 else 0\n",
    "        for classname in ['ai', 'human']\n",
    "    }\n",
    "\n",
    "    overall_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=[0, 1])\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    fpr = {}\n",
    "    for i, classname in enumerate(['ai', 'human']):\n",
    "        FP = cm[:, i].sum() - cm[i, i]\n",
    "        TN = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "        fpr[classname] = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "\n",
    "    # Logging\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_lines = [f\"===== Evaluation at {timestamp} =====\\n\"]\n",
    "\n",
    "    if hyperparams:\n",
    "        log_lines.append(\"Hyperparameters:\")\n",
    "        for key, value in hyperparams.items():\n",
    "            log_lines.append(f\"{key}: {value}\")\n",
    "    else:\n",
    "        log_lines.append(\"No hyperparameters provided.\")\n",
    "    log_lines.append(\"\")\n",
    "\n",
    "    log_lines.append(\"Accuracy per class:\")\n",
    "    for classname, acc in accuracy_per_class.items():\n",
    "        log_lines.append(f\"{classname}: {acc:.4f}\")\n",
    "    log_lines.append(\"\\nPrecision, Recall, F1:\")\n",
    "    for i, classname in enumerate(['ai', 'human']):\n",
    "        log_lines.append(f\"{classname} → Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1: {f1[i]:.4f}\")\n",
    "    log_lines.append(\"\\nFalse Positive Rate:\")\n",
    "    for classname, rate in fpr.items():\n",
    "        log_lines.append(f\"{classname}: {rate:.4f}\")\n",
    "    log_lines.append(f\"\\nOverall Accuracy: {overall_accuracy:.4f}\")\n",
    "    log_lines.append(f\"Average Inference Time per Sample: {avg_inference_time:.6f} seconds\")\n",
    "    log_lines.append(\"=\" * 40 + \"\\n\\n\")\n",
    "\n",
    "    print(\"\\n\".join(log_lines))\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(\"\\n\".join(log_lines))\n",
    "\n",
    "    return overall_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ba7486-9b85-46cc-89b5-a83662fe7f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [21:06<00:00,  5.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           filename   prob_ai  prob_human  true_label  \\\n",
      "0  U1665RN_segment_1-Chromagram.png  0.998740    0.001260           0   \n",
      "1            H21242N-Chromagram.png  0.033304    0.966696           1   \n",
      "2  S3181RN_segment_1-Chromagram.png  0.999997    0.000003           0   \n",
      "3             H5984N-Chromagram.png  0.054724    0.945276           1   \n",
      "4  S3320RN_segment_2-Chromagram.png  0.676560    0.323440           0   \n",
      "\n",
      "   pred_label  \n",
      "0           0  \n",
      "1           1  \n",
      "2           0  \n",
      "3           1  \n",
      "4           0  \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "results = []\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    inputs, labels, filenames = batch \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "        for i in range(len(filenames)):\n",
    "            results.append({\n",
    "                \"filename\": filenames[i],\n",
    "                \"prob_ai\": probs[i][0].item(),\n",
    "                \"prob_human\": probs[i][1].item(),\n",
    "                \"true_label\": labels[i].item(),\n",
    "                \"pred_label\": torch.argmax(probs[i]).item()\n",
    "            })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"chromagram_test_large_with_aug_predictions.csv\", index=False)\n",
    "\n",
    "# Preview results\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "349ae333-5948-482e-a9b7-6368c50258cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cur_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab43cab-32a6-4f62-b748-2c6c3651ce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Evaluation at 2025-05-26 17:47:17 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.001\n",
      "epochs: 5\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.8886\n",
      "human: 0.8850\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.8975, Recall: 0.8886, F1: 0.8930\n",
      "human → Precision: 0.8752, Recall: 0.8850, F1: 0.8801\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.1150\n",
      "human: 0.1114\n",
      "\n",
      "Overall Accuracy: 0.8869\n",
      "Average Inference Time per Sample: 0.111508 seconds\n",
      "========================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8869293308317698"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": num_epochs,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"model\": model.__class__.__name__,\n",
    "}\n",
    "\n",
    "evaluate_model(model, test_loader, device, hyperparams=hyperparams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528345df-fdf8-4be5-96f0-8521ad6f6f0d",
   "metadata": {},
   "source": [
    "HYPERPARAM SEARCH BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed1c5e6-f878-46b7-ab31-2d0fa6405b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Trial 1/10: LR=0.0001, WD=1e-07, Epochs=10 ===\n",
      "Epoch [1/10], train loss: 0.4115, train acc: 0.8149, val loss: 0.3301, val acc: 0.8528\n",
      "Epoch [2/10], train loss: 0.2974, train acc: 0.8689, val loss: 0.3094, val acc: 0.8661\n",
      "Epoch [3/10], train loss: 0.2586, train acc: 0.8900, val loss: 0.2919, val acc: 0.8762\n",
      "Epoch [4/10], train loss: 0.2297, train acc: 0.9052, val loss: 0.2876, val acc: 0.8766\n",
      "Epoch [5/10], train loss: 0.1986, train acc: 0.9201, val loss: 0.2885, val acc: 0.8801\n",
      "Epoch [6/10], train loss: 0.1710, train acc: 0.9313, val loss: 0.2928, val acc: 0.8783\n",
      "Epoch [7/10], train loss: 0.1384, train acc: 0.9496, val loss: 0.3015, val acc: 0.8797\n",
      "Epoch [8/10], train loss: 0.1096, train acc: 0.9625, val loss: 0.3241, val acc: 0.8762\n",
      "Epoch [9/10], train loss: 0.0821, train acc: 0.9754, val loss: 0.3491, val acc: 0.8768\n",
      "Epoch [10/10], train loss: 0.0564, train acc: 0.9852, val loss: 0.3726, val acc: 0.8770\n",
      "===== Evaluation at 2025-05-22 05:34:19 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.0001\n",
      "epochs: 10\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-07\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.6957\n",
      "human: 0.9314\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.7526, Recall: 0.6957, F1: 0.7231\n",
      "human → Precision: 0.9108, Recall: 0.9314, F1: 0.9210\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.0686\n",
      "human: 0.3043\n",
      "\n",
      "Overall Accuracy: 0.8770\n",
      "Average Inference Time per Sample: 0.059708 seconds\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "=== Trial 2/10: LR=0.001, WD=1e-07, Epochs=5 ===\n",
      "Epoch [1/5], train loss: 0.3152, train acc: 0.8607, val loss: 0.2794, val acc: 0.8766\n",
      "Epoch [2/5], train loss: 0.2177, train acc: 0.9079, val loss: 0.2647, val acc: 0.8914\n",
      "Epoch [3/5], train loss: 0.1458, train acc: 0.9426, val loss: 0.2768, val acc: 0.8861\n",
      "Epoch [4/5], train loss: 0.0932, train acc: 0.9642, val loss: 0.3172, val acc: 0.8869\n",
      "Epoch [5/5], train loss: 0.0602, train acc: 0.9778, val loss: 0.5037, val acc: 0.8789\n",
      "===== Evaluation at 2025-05-22 07:57:14 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.001\n",
      "epochs: 5\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-07\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.5365\n",
      "human: 0.9816\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.8973, Recall: 0.5365, F1: 0.6715\n",
      "human → Precision: 0.8759, Recall: 0.9816, F1: 0.9257\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.0184\n",
      "human: 0.4635\n",
      "\n",
      "Overall Accuracy: 0.8789\n",
      "Average Inference Time per Sample: 0.059529 seconds\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "=== Trial 3/10: LR=0.001, WD=1e-06, Epochs=5 ===\n",
      "Epoch [1/5], train loss: 0.3173, train acc: 0.8633, val loss: 0.2624, val acc: 0.8877\n",
      "Epoch [2/5], train loss: 0.2091, train acc: 0.9130, val loss: 0.2575, val acc: 0.8908\n",
      "Epoch [3/5], train loss: 0.1404, train acc: 0.9433, val loss: 0.2812, val acc: 0.8904\n",
      "Epoch [4/5], train loss: 0.0866, train acc: 0.9678, val loss: 0.3228, val acc: 0.8893\n",
      "Epoch [5/5], train loss: 0.0517, train acc: 0.9811, val loss: 0.3654, val acc: 0.8953\n",
      "===== Evaluation at 2025-05-22 10:20:21 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.001\n",
      "epochs: 5\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.8025\n",
      "human: 0.9231\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.7580, Recall: 0.8025, F1: 0.7796\n",
      "human → Precision: 0.9397, Recall: 0.9231, F1: 0.9313\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.0769\n",
      "human: 0.1975\n",
      "\n",
      "Overall Accuracy: 0.8953\n",
      "Average Inference Time per Sample: 0.060525 seconds\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "=== Trial 4/10: LR=0.0005, WD=1e-06, Epochs=10 ===\n",
      "Epoch [1/10], train loss: 0.3329, train acc: 0.8535, val loss: 0.2683, val acc: 0.8834\n",
      "Epoch [2/10], train loss: 0.2272, train acc: 0.9036, val loss: 0.2612, val acc: 0.8879\n",
      "Epoch [3/10], train loss: 0.1576, train acc: 0.9371, val loss: 0.2654, val acc: 0.8908\n",
      "Epoch [4/10], train loss: 0.0827, train acc: 0.9697, val loss: 0.3298, val acc: 0.8824\n",
      "Epoch [5/10], train loss: 0.0430, train acc: 0.9862, val loss: 0.3823, val acc: 0.8871\n",
      "Epoch [6/10], train loss: 0.0347, train acc: 0.9879, val loss: 0.4161, val acc: 0.8824\n",
      "Epoch [7/10], train loss: 0.0299, train acc: 0.9898, val loss: 0.4236, val acc: 0.8852\n",
      "Epoch [8/10], train loss: 0.0222, train acc: 0.9929, val loss: 0.4390, val acc: 0.8815\n",
      "Epoch [9/10], train loss: 0.0182, train acc: 0.9936, val loss: 0.5015, val acc: 0.8906\n",
      "Epoch [10/10], train loss: 0.0169, train acc: 0.9941, val loss: 0.4783, val acc: 0.8822\n",
      "===== Evaluation at 2025-05-22 15:26:11 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.0005\n",
      "epochs: 10\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0005\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.7020\n",
      "human: 0.9362\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.7675, Recall: 0.7020, F1: 0.7333\n",
      "human → Precision: 0.9128, Recall: 0.9362, F1: 0.9244\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.0638\n",
      "human: 0.2980\n",
      "\n",
      "Overall Accuracy: 0.8822\n",
      "Average Inference Time per Sample: 0.066160 seconds\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "=== Trial 5/10: LR=0.0001, WD=1e-07, Epochs=20 ===\n",
      "Epoch [1/20], train loss: 0.4041, train acc: 0.8209, val loss: 0.3292, val acc: 0.8561\n",
      "Epoch [2/20], train loss: 0.2980, train acc: 0.8699, val loss: 0.3038, val acc: 0.8719\n",
      "Epoch [3/20], train loss: 0.2620, train acc: 0.8867, val loss: 0.2977, val acc: 0.8705\n",
      "Epoch [4/20], train loss: 0.2324, train acc: 0.9039, val loss: 0.2897, val acc: 0.8785\n",
      "Epoch [5/20], train loss: 0.2003, train acc: 0.9192, val loss: 0.2896, val acc: 0.8824\n",
      "Epoch [6/20], train loss: 0.1734, train acc: 0.9331, val loss: 0.2946, val acc: 0.8813\n",
      "Epoch [7/20], train loss: 0.1390, train acc: 0.9502, val loss: 0.3070, val acc: 0.8762\n",
      "Epoch [8/20], train loss: 0.1118, train acc: 0.9609, val loss: 0.3223, val acc: 0.8756\n",
      "Epoch [9/20], train loss: 0.0849, train acc: 0.9728, val loss: 0.3479, val acc: 0.8700\n",
      "Epoch [10/20], train loss: 0.0597, train acc: 0.9839, val loss: 0.3734, val acc: 0.8764\n",
      "Epoch [11/20], train loss: 0.0422, train acc: 0.9890, val loss: 0.4033, val acc: 0.8707\n",
      "Epoch [12/20], train loss: 0.0307, train acc: 0.9927, val loss: 0.4228, val acc: 0.8737\n",
      "Epoch [13/20], train loss: 0.0215, train acc: 0.9954, val loss: 0.4580, val acc: 0.8709\n",
      "Epoch [14/20], train loss: 0.0185, train acc: 0.9963, val loss: 0.4583, val acc: 0.8715\n",
      "Epoch [15/20], train loss: 0.0155, train acc: 0.9967, val loss: 0.4848, val acc: 0.8698\n",
      "Epoch [16/20], train loss: 0.0122, train acc: 0.9978, val loss: 0.4894, val acc: 0.8707\n",
      "Epoch [17/20], train loss: 0.0097, train acc: 0.9985, val loss: 0.5255, val acc: 0.8733\n",
      "Epoch [18/20], train loss: 0.0116, train acc: 0.9973, val loss: 0.5131, val acc: 0.8705\n",
      "Epoch [19/20], train loss: 0.0085, train acc: 0.9985, val loss: 0.5227, val acc: 0.8721\n",
      "Epoch [20/20], train loss: 0.0081, train acc: 0.9984, val loss: 0.5270, val acc: 0.8725\n",
      "===== Evaluation at 2025-05-23 01:08:19 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.0001\n",
      "epochs: 20\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-07\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.6779\n",
      "human: 0.9309\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.7463, Recall: 0.6779, F1: 0.7105\n",
      "human → Precision: 0.9060, Recall: 0.9309, F1: 0.9183\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.0691\n",
      "human: 0.3221\n",
      "\n",
      "Overall Accuracy: 0.8725\n",
      "Average Inference Time per Sample: 0.060097 seconds\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "=== Trial 6/10: LR=0.0001, WD=1e-06, Epochs=20 ===\n",
      "Epoch [1/20], train loss: 0.4126, train acc: 0.8201, val loss: 0.3418, val acc: 0.8448\n",
      "Epoch [2/20], train loss: 0.3045, train acc: 0.8677, val loss: 0.3096, val acc: 0.8610\n",
      "Epoch [3/20], train loss: 0.2658, train acc: 0.8866, val loss: 0.3012, val acc: 0.8707\n",
      "Epoch [4/20], train loss: 0.2360, train acc: 0.9022, val loss: 0.2906, val acc: 0.8742\n",
      "Epoch [5/20], train loss: 0.2070, train acc: 0.9164, val loss: 0.2905, val acc: 0.8756\n",
      "Epoch [6/20], train loss: 0.1811, train acc: 0.9273, val loss: 0.2908, val acc: 0.8729\n",
      "Epoch [7/20], train loss: 0.1494, train acc: 0.9448, val loss: 0.3080, val acc: 0.8746\n",
      "Epoch [8/20], train loss: 0.1194, train acc: 0.9572, val loss: 0.3150, val acc: 0.8781\n",
      "Epoch [9/20], train loss: 0.0934, train acc: 0.9686, val loss: 0.3337, val acc: 0.8694\n",
      "Epoch [10/20], train loss: 0.0677, train acc: 0.9800, val loss: 0.3530, val acc: 0.8703\n",
      "Epoch [11/20], train loss: 0.0476, train acc: 0.9882, val loss: 0.3775, val acc: 0.8735\n",
      "Epoch [12/20], train loss: 0.0353, train acc: 0.9916, val loss: 0.3953, val acc: 0.8680\n",
      "Epoch [13/20], train loss: 0.0279, train acc: 0.9935, val loss: 0.4269, val acc: 0.8721\n",
      "Epoch [14/20], train loss: 0.0214, train acc: 0.9959, val loss: 0.4309, val acc: 0.8758\n",
      "Epoch [15/20], train loss: 0.0173, train acc: 0.9962, val loss: 0.4502, val acc: 0.8739\n",
      "Epoch [16/20], train loss: 0.0125, train acc: 0.9978, val loss: 0.4723, val acc: 0.8733\n",
      "Epoch [17/20], train loss: 0.0100, train acc: 0.9989, val loss: 0.4751, val acc: 0.8750\n",
      "Epoch [18/20], train loss: 0.0114, train acc: 0.9978, val loss: 0.4962, val acc: 0.8692\n",
      "Epoch [19/20], train loss: 0.0084, train acc: 0.9989, val loss: 0.5125, val acc: 0.8766\n",
      "Epoch [20/20], train loss: 0.0073, train acc: 0.9988, val loss: 0.5082, val acc: 0.8764\n",
      "===== Evaluation at 2025-05-23 04:48:33 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.0001\n",
      "epochs: 20\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.7144\n",
      "human: 0.9250\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.7408, Recall: 0.7144, F1: 0.7274\n",
      "human → Precision: 0.9152, Recall: 0.9250, F1: 0.9201\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.0750\n",
      "human: 0.2856\n",
      "\n",
      "Overall Accuracy: 0.8764\n",
      "Average Inference Time per Sample: 0.015568 seconds\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "=== Trial 7/10: LR=0.0005, WD=1e-08, Epochs=10 ===\n",
      "Epoch [1/10], train loss: 0.3293, train acc: 0.8538, val loss: 0.2790, val acc: 0.8795\n",
      "Epoch [2/10], train loss: 0.2262, train acc: 0.9064, val loss: 0.2582, val acc: 0.8912\n",
      "Epoch [3/10], train loss: 0.1640, train acc: 0.9360, val loss: 0.2773, val acc: 0.8881\n",
      "Epoch [4/10], train loss: 0.0864, train acc: 0.9693, val loss: 0.3497, val acc: 0.8820\n",
      "Epoch [5/10], train loss: 0.0521, train acc: 0.9822, val loss: 0.3703, val acc: 0.8807\n",
      "Epoch [6/10], train loss: 0.0323, train acc: 0.9891, val loss: 0.4322, val acc: 0.8754\n",
      "Epoch [7/10], train loss: 0.0260, train acc: 0.9911, val loss: 0.4538, val acc: 0.8826\n",
      "Epoch [8/10], train loss: 0.0225, train acc: 0.9921, val loss: 0.4414, val acc: 0.8898\n",
      "Epoch [9/10], train loss: 0.0202, train acc: 0.9931, val loss: 0.4654, val acc: 0.8803\n",
      "Epoch [10/10], train loss: 0.0144, train acc: 0.9955, val loss: 0.4937, val acc: 0.8867\n",
      "===== Evaluation at 2025-05-23 06:04:29 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.0005\n",
      "epochs: 10\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0005\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-08\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.7269\n",
      "human: 0.9346\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.7693, Recall: 0.7269, F1: 0.7475\n",
      "human → Precision: 0.9194, Recall: 0.9346, F1: 0.9269\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.0654\n",
      "human: 0.2731\n",
      "\n",
      "Overall Accuracy: 0.8867\n",
      "Average Inference Time per Sample: 0.015533 seconds\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "=== Trial 8/10: LR=0.001, WD=1e-07, Epochs=20 ===\n",
      "Epoch [1/20], train loss: 0.3207, train acc: 0.8612, val loss: 0.2668, val acc: 0.8848\n",
      "Epoch [2/20], train loss: 0.2132, train acc: 0.9114, val loss: 0.2475, val acc: 0.8930\n",
      "Epoch [3/20], train loss: 0.1423, train acc: 0.9449, val loss: 0.2896, val acc: 0.8881\n",
      "Epoch [4/20], train loss: 0.0883, train acc: 0.9658, val loss: 0.3165, val acc: 0.8854\n",
      "Epoch [5/20], train loss: 0.0627, train acc: 0.9773, val loss: 0.3762, val acc: 0.8898\n",
      "Epoch [6/20], train loss: 0.0399, train acc: 0.9845, val loss: 0.3793, val acc: 0.8850\n",
      "Epoch [7/20], train loss: 0.0364, train acc: 0.9865, val loss: 0.3887, val acc: 0.8922\n",
      "Epoch [8/20], train loss: 0.0398, train acc: 0.9847, val loss: 0.4276, val acc: 0.8863\n",
      "Epoch [9/20], train loss: 0.0239, train acc: 0.9913, val loss: 0.4497, val acc: 0.8922\n",
      "Epoch [10/20], train loss: 0.0237, train acc: 0.9916, val loss: 0.4491, val acc: 0.8982\n",
      "Epoch [11/20], train loss: 0.0156, train acc: 0.9941, val loss: 0.5342, val acc: 0.8902\n",
      "Epoch [12/20], train loss: 0.0190, train acc: 0.9932, val loss: 0.4497, val acc: 0.8873\n",
      "Epoch [13/20], train loss: 0.0123, train acc: 0.9957, val loss: 0.4991, val acc: 0.8974\n",
      "Epoch [14/20], train loss: 0.0087, train acc: 0.9968, val loss: 0.5251, val acc: 0.8959\n",
      "Epoch [15/20], train loss: 0.0091, train acc: 0.9965, val loss: 0.4831, val acc: 0.8967\n",
      "Epoch [16/20], train loss: 0.0092, train acc: 0.9971, val loss: 0.4590, val acc: 0.8998\n",
      "Epoch [17/20], train loss: 0.0067, train acc: 0.9978, val loss: 0.5436, val acc: 0.8971\n",
      "Epoch [18/20], train loss: 0.0068, train acc: 0.9979, val loss: 0.4856, val acc: 0.8949\n",
      "Epoch [19/20], train loss: 0.0051, train acc: 0.9985, val loss: 0.5437, val acc: 0.8971\n",
      "Epoch [20/20], train loss: 0.0088, train acc: 0.9966, val loss: 0.6855, val acc: 0.8891\n",
      "===== Evaluation at 2025-05-23 08:34:57 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.001\n",
      "epochs: 20\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-07\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.6557\n",
      "human: 0.9592\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.8281, Recall: 0.6557, F1: 0.7319\n",
      "human → Precision: 0.9028, Recall: 0.9592, F1: 0.9301\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.0408\n",
      "human: 0.3443\n",
      "\n",
      "Overall Accuracy: 0.8891\n",
      "Average Inference Time per Sample: 0.016013 seconds\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "=== Trial 9/10: LR=0.001, WD=1e-06, Epochs=10 ===\n",
      "Epoch [1/10], train loss: 0.3140, train acc: 0.8642, val loss: 0.2813, val acc: 0.8809\n",
      "Epoch [2/10], train loss: 0.2098, train acc: 0.9141, val loss: 0.2983, val acc: 0.8805\n",
      "Epoch [3/10], train loss: 0.1459, train acc: 0.9422, val loss: 0.2999, val acc: 0.8799\n",
      "Epoch [4/10], train loss: 0.0942, train acc: 0.9633, val loss: 0.3273, val acc: 0.8863\n",
      "Epoch [5/10], train loss: 0.0546, train acc: 0.9801, val loss: 0.4270, val acc: 0.8729\n",
      "Epoch [6/10], train loss: 0.0498, train acc: 0.9808, val loss: 0.4381, val acc: 0.8844\n",
      "Epoch [7/10], train loss: 0.0380, train acc: 0.9860, val loss: 0.4081, val acc: 0.8838\n",
      "Epoch [8/10], train loss: 0.0283, train acc: 0.9898, val loss: 0.4645, val acc: 0.8906\n",
      "Epoch [9/10], train loss: 0.0327, train acc: 0.9877, val loss: 0.4783, val acc: 0.8832\n",
      "Epoch [10/10], train loss: 0.0189, train acc: 0.9933, val loss: 0.5040, val acc: 0.8856\n",
      "===== Evaluation at 2025-05-23 09:50:53 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.001\n",
      "epochs: 10\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.7384\n",
      "human: 0.9298\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.7594, Recall: 0.7384, F1: 0.7488\n",
      "human → Precision: 0.9222, Recall: 0.9298, F1: 0.9260\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.0702\n",
      "human: 0.2616\n",
      "\n",
      "Overall Accuracy: 0.8856\n",
      "Average Inference Time per Sample: 0.015800 seconds\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "=== Trial 10/10: LR=0.0001, WD=1e-07, Epochs=5 ===\n",
      "Epoch [1/5], train loss: 0.3991, train acc: 0.8199, val loss: 0.3204, val acc: 0.8583\n",
      "Epoch [2/5], train loss: 0.2972, train acc: 0.8694, val loss: 0.2975, val acc: 0.8733\n",
      "Epoch [3/5], train loss: 0.2636, train acc: 0.8890, val loss: 0.2860, val acc: 0.8764\n",
      "Epoch [4/5], train loss: 0.2350, train acc: 0.9014, val loss: 0.2839, val acc: 0.8787\n",
      "Epoch [5/5], train loss: 0.2046, train acc: 0.9186, val loss: 0.2842, val acc: 0.8791\n",
      "===== Evaluation at 2025-05-23 10:29:21 =====\n",
      "\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.0001\n",
      "epochs: 5\n",
      "optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 1e-07\n",
      ")\n",
      "model: ResNet\n",
      "\n",
      "Accuracy per class:\n",
      "ai: 0.6477\n",
      "human: 0.9485\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.7904, Recall: 0.6477, F1: 0.7120\n",
      "human → Precision: 0.8997, Recall: 0.9485, F1: 0.9235\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.0515\n",
      "human: 0.3523\n",
      "\n",
      "Overall Accuracy: 0.8791\n",
      "Average Inference Time per Sample: 0.015703 seconds\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "Best validation accuracy: 0.8952987066310819\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter search space\n",
    "learning_rates = [1e-3, 1e-4, 5e-4]\n",
    "weight_decays = [1e-6, 1e-7, 1e-8]\n",
    "epochs_list = [5, 10, 20] \n",
    "\n",
    "# Generate hyperparameter combinations and randomly select 10\n",
    "param_combinations = list(product(learning_rates, weight_decays, epochs_list))\n",
    "random.shuffle(param_combinations)\n",
    "hyperparam_trials = param_combinations[:10]\n",
    "\n",
    "# Run randomized search\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "\n",
    "for i, (lr, wd, epochs) in enumerate(hyperparam_trials):\n",
    "    print(f\"\\n=== Trial {i+1}/10: LR={lr}, WD={wd}, Epochs={epochs} ===\")\n",
    "\n",
    "    model = get_model()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Use an optimizer like Adam or SGD (adjust based on your requirement)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "    \n",
    "    # Train the model\n",
    "    train(model, train_loader, val_loader, criterion, optimizer, epochs)\n",
    "\n",
    "    hyperparams = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": epochs,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"model\": model.__class__.__name__,\n",
    "    }\n",
    "    \n",
    "    val_acc = evaluate_model(model, val_loader, device, hyperparams=hyperparams)\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model = model\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    \n",
    "print(\"\\nBest validation accuracy:\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9ec0365-7592-472b-a320-65ce25b593a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 443/443 [12:32<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     filename   prob_ai  prob_human  \\\n",
      "0  U1559RN_segment_1_stretched-Chromagram.png  0.012985    0.987015   \n",
      "1    U1242RN_segment_2_shifted-Chromagram.png  0.002274    0.997726   \n",
      "2  S4918RN_segment_2_stretched-Chromagram.png  0.998038    0.001962   \n",
      "3    S3971RN_segment_1_shifted-Chromagram.png  0.000172    0.999828   \n",
      "4     S730RN_segment_2_shifted-Chromagram.png  0.007688    0.992312   \n",
      "\n",
      "   true_label  pred_label  \n",
      "0           1           1  \n",
      "1           1           1  \n",
      "2           1           0  \n",
      "3           1           1  \n",
      "4           1           1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.load_state_dict(torch.load(\"best_model.pt\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "for batch in tqdm(ai_aug_test_loader):\n",
    "    inputs, labels, filenames = batch \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "        for i in range(len(filenames)):\n",
    "            results.append({\n",
    "                \"filename\": filenames[i], \n",
    "                \"prob_ai\": probs[i][0].item(),\n",
    "                \"prob_human\": probs[i][1].item(),\n",
    "                \"true_label\": labels[i].item(),\n",
    "                \"pred_label\": torch.argmax(probs[i]).item()\n",
    "            })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"best_chrm_ai_aug_test_predictions.csv\", index=False)\n",
    "\n",
    "# Preview results\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "139a8301-bb29-4395-bd7a-af6f3ca61c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/sg2121/fyp/aimusicdetector/venvNew/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct_pred = {classname: 0 for classname in ['ai', 'human']}\n",
    "total_pred = {classname: 0 for classname in ['ai', 'human']}\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, filenames in ai_aug_test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        for label, prediction in zip(labels, preds):\n",
    "            classname = 'ai' if label.item() == 0 else 'human'\n",
    "            if label == prediction:\n",
    "                correct_pred[classname] += 1\n",
    "            total_pred[classname] += 1\n",
    "\n",
    "end_time = time.time()\n",
    "avg_inference_time = (end_time - start_time) / len(test_loader.dataset)\n",
    "\n",
    "accuracy_per_class = {\n",
    "    classname: correct_pred[classname] / total_pred[classname]\n",
    "    if total_pred[classname] > 0 else 0\n",
    "    for classname in ['ai', 'human']\n",
    "}\n",
    "\n",
    "overall_accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=[0, 1])\n",
    "cm = confusion_matrix(all_labels, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12867d43-da18-415b-b482-be5bbbeb7018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0]\n",
      " [7561 6588]]\n",
      "Accuracy per class:\n",
      "ai: 0.0000\n",
      "human: 0.4656\n",
      "\n",
      "Precision, Recall, F1:\n",
      "ai → Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "human → Precision: 1.0000, Recall: 0.4656, F1: 0.6354\n",
      "\n",
      "False Positive Rate:\n",
      "ai: 0.5344\n",
      "human: 0.0000\n",
      "\n",
      "Overall Accuracy: 0.4656\n",
      "Average Inference Time per Sample: 0.046648 seconds\n",
      "========================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm)\n",
    "fpr = {}\n",
    "for i, classname in enumerate(['ai', 'human']):\n",
    "    FP = cm[:, i].sum() - cm[i, i]\n",
    "    TN = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "    fpr[classname] = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "\n",
    "print(\"Accuracy per class:\")\n",
    "for classname, acc in accuracy_per_class.items():\n",
    "    print(f\"{classname}: {acc:.4f}\")\n",
    "print(\"\\nPrecision, Recall, F1:\")\n",
    "for i, classname in enumerate(['ai', 'human']):\n",
    "    print(f\"{classname} → Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1: {f1[i]:.4f}\")\n",
    "print(\"\\nFalse Positive Rate:\")\n",
    "for classname, rate in fpr.items():\n",
    "    print(f\"{classname}: {rate:.4f}\")\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy:.4f}\")\n",
    "print(f\"Average Inference Time per Sample: {avg_inference_time:.6f} seconds\")\n",
    "print(\"=\" * 40 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a5d8233-b2a4-4d99-885f-003ff31a6768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: 6588/14149 (46.56%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"best_chrm_ai_aug_test_predictions.csv\") \n",
    "\n",
    "total = len(df)\n",
    "\n",
    "# Count where prediction is correct\n",
    "correct = (df[\"true_label\"] == df[\"pred_label\"]).sum()\n",
    "\n",
    "print(f\"Correct predictions: {correct}/{total} ({correct/total:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c36ab-1bad-43ef-9480-513ac03e5900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
