{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec86650-2c1c-4a81-9ddf-081016942431",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AdamW' from 'transformers' (/vol/bitbucket/sg2121/fyp/aimusicdetector/venvNew/lib/python3.12/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     accuracy_score, precision_recall_fscore_support, confusion_matrix\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdamW\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'AdamW' from 'transformers' (/vol/bitbucket/sg2121/fyp/aimusicdetector/venvNew/lib/python3.12/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, get_scheduler\n",
    "\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    ")\n",
    "import time\n",
    "\n",
    "from transformers import AdamW\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd8f69-b85b-4c57-9fd4-a526c12168ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained DistilBERT tokenizer and model for binary classification\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb4839-30a0-4a47-b616-1417a1bde112",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a06458-c78c-4273-8a84-f0d55415187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths for the segments and lyrics\n",
    "ai_segments_path = \"/vol/bitbucket/sg2121/fypdataset/dataset/normal_data/ai\"\n",
    "human_segments_path = \"/vol/bitbucket/sg2121/fypdataset/dataset/normal_data/human\"\n",
    "ai_lyrics_path = \"/data/sg2121/fypdataset/dataset/lyrics/ai\"\n",
    "human_lyrics_path = \"/data/sg2121/fypdataset/dataset/lyrics/human\"\n",
    "\n",
    "# Helper function to read file paths from a text file\n",
    "def read_file_paths(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        return [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Read all file paths from the text files\n",
    "train_files = read_file_paths('/data/sg2121/aimusicdetector/train_test_split/train_files.txt')\n",
    "val_files = read_file_paths('/data/sg2121/aimusicdetector/train_test_split/val_files.txt')\n",
    "test_files = read_file_paths('/data/sg2121/aimusicdetector/train_test_split/test_files.txt')\n",
    "\n",
    "# Function to convert segment file path to lyric file path\n",
    "def convert_to_lyric_path(file_path, is_ai):\n",
    "    if is_ai:\n",
    "        if file_path.startswith(ai_segments_path):\n",
    "            base_lyrics_path = ai_lyrics_path\n",
    "        else:\n",
    "            return\n",
    "    else:\n",
    "        if file_path.startswith(human_segments_path):\n",
    "            base_lyrics_path = human_lyrics_path\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    # Convert filename to lyrics filename\n",
    "    file_name = os.path.basename(file_path).replace('.mp3', '_lyrics.txt')\n",
    "    return os.path.join(base_lyrics_path, file_name)\n",
    "\n",
    "\n",
    "# Process the file lists and create tuples of (lyric_path, label)\n",
    "def process_file_paths(file_paths, is_ai):\n",
    "    return [(convert_to_lyric_path(file_path, is_ai), 0 if is_ai else 1) for file_path in file_paths]\n",
    "\n",
    "# Convert all file paths from the train, validation, and test sets\n",
    "ai_train_files = process_file_paths(train_files, is_ai=True)\n",
    "human_train_files = process_file_paths(train_files, is_ai=False)\n",
    "\n",
    "ai_val_files = process_file_paths(val_files, is_ai=True)\n",
    "human_val_files = process_file_paths(val_files, is_ai=False)\n",
    "\n",
    "ai_test_files = process_file_paths(test_files, is_ai=True)\n",
    "human_test_files = process_file_paths(test_files, is_ai=False)\n",
    "\n",
    "ai_train_files = [(path, label) for path, label in ai_train_files if path is not None]\n",
    "human_train_files = [(path, label) for path, label in human_train_files if path is not None]\n",
    "\n",
    "ai_val_files = [(path, label) for path, label in ai_val_files if path is not None]\n",
    "human_val_files = [(path, label) for path, label in human_val_files if path is not None]\n",
    "\n",
    "ai_test_files = [(path, label) for path, label in ai_test_files if path is not None]\n",
    "human_test_files = [(path, label) for path, label in human_test_files if path is not None]\n",
    "\n",
    "\n",
    "# Combine all files into a single list for each split\n",
    "train_files_combined = ai_train_files + human_train_files\n",
    "val_files_combined = ai_val_files + human_val_files\n",
    "test_files_combined = ai_test_files + human_test_files\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(train_files_combined)\n",
    "random.shuffle(val_files_combined)\n",
    "random.shuffle(test_files_combined)\n",
    "\n",
    "# Check the splits\n",
    "print(f\"Training set size: {len(train_files_combined)}\")\n",
    "print(f\"Validation set size: {len(val_files_combined)}\")\n",
    "print(f\"Test set size: {len(test_files_combined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4b5266b-99d9-4ac7-86dd-7dfaacc3b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, file_paths, tokenizer, max_length=512):\n",
    "        self.file_paths = file_paths\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.file_paths[idx]\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': torch.tensor(label, dtype=torch.long),\n",
    "            'filename': os.path.basename(file_path)  # This is important\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6245a977-8c91-4e6b-a07c-661ece9cf1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input IDs: tensor([ 101, 4658, 1010, 2023, 4569, 2729, 2395,  102,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Sample attention mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Sample label: 0\n"
     ]
    }
   ],
   "source": [
    "# Create datasets for training, validation, and testing\n",
    "train_dataset = LyricsDataset(train_files_combined, tokenizer)\n",
    "val_dataset = LyricsDataset(val_files_combined, tokenizer)\n",
    "test_dataset = LyricsDataset(test_files_combined, tokenizer)\n",
    "\n",
    "# Create DataLoader for each dataset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "339c49dd-e77d-40e8-90a4-c336aa0da749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 74/74 [00:10<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Loss: 0.37104618549346924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4535, Accuracy: 0.7937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 74/74 [00:10<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Loss: 0.12233859300613403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4206, Accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 74/74 [00:10<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Loss: 0.31677931547164917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 22.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4282, Accuracy: 0.8254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up the optimizer and training loop\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",                     \n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,               \n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):  \n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # Ensure batch is a dictionary of tensors\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update learning rate\n",
    "        lr_scheduler.step() \n",
    "    \n",
    "    print(f\"Epoch {epoch + 1} completed. Loss: {loss.item()}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss += outputs.loss.item()\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    accuracy = correct_predictions / len(val_files)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fba58e6-d6c1-4528-ac40-141ae5388246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 20.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader, device, output_csv=\"test_predictions.csv\", class_names=[\"AI\", \"Human\"]):\n",
    "    \"\"\"\n",
    "    Evaluates a binary classification model and saves predictions to CSV.\n",
    "\n",
    "    Args:\n",
    "        model: The trained PyTorch model.\n",
    "        dataloader: DataLoader for the test set.\n",
    "        device: 'cuda' or 'cpu'.\n",
    "        output_csv: Filename to save the CSV of predictions.\n",
    "        class_names: List of class names in the order of label indices.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = []\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    total_inference_time = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        filenames = batch['filename']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            start_time = time.time()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            inference_time = time.time() - start_time\n",
    "            total_inference_time += inference_time\n",
    "\n",
    "            probs = F.softmax(outputs.logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "\n",
    "            for i in range(len(filenames)):\n",
    "                results.append({\n",
    "                    \"filename\": filenames[i],\n",
    "                    \"prob_\" + class_names[0].lower(): probs[i][0].item(),\n",
    "                    \"prob_\" + class_names[1].lower(): probs[i][1].item(),\n",
    "                    \"true_label\": labels[i].item(),\n",
    "                    \"pred_label\": preds[i].item()\n",
    "                })\n",
    "\n",
    "    # Save predictions\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    avg_inference_time = total_inference_time / total_predictions\n",
    "\n",
    "    # Compute False Positive Rate\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n=== Overall Metrics ===\")\n",
    "    print(f\"Accuracy         : {accuracy:.4f}\")\n",
    "    print(f\"Precision        : {precision:.4f}\")\n",
    "    print(f\"Recall           : {recall:.4f}\")\n",
    "    print(f\"F1 Score         : {f1:.4f}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n",
    "    print(f\"Average Inference Time per Sample: {avg_inference_time * 1000:.2f} ms\")\n",
    "\n",
    "    print(f\"\\n=== Class-wise Metrics ===\")\n",
    "    for i, label in enumerate(class_names):\n",
    "        class_accuracy = conf_matrix[i][i] / conf_matrix.sum(axis=1)[i]\n",
    "        print(f\"{label}: Precision={precision_per_class[i]:.4f}, Recall={recall_per_class[i]:.4f}, \"\n",
    "              f\"F1={f1_per_class[i]:.4f}, Accuracy={class_accuracy:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"fpr\": fpr,\n",
    "        \"avg_inference_time\": avg_inference_time,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"per_class\": {\n",
    "            class_names[i]: {\n",
    "                \"precision\": precision_per_class[i],\n",
    "                \"recall\": recall_per_class[i],\n",
    "                \"f1\": f1_per_class[i],\n",
    "                \"accuracy\": conf_matrix[i][i] / conf_matrix.sum(axis=1)[i]\n",
    "            }\n",
    "            for i in range(len(class_names))\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23568cac-0543-4a58-92df-625cf3dcae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_model(model, test_dataloader, device, output_csv=\"lyrics_test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345db706-88da-4d89-8f60-0973d59ad8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"learning_rate\": [5e-5, 3e-5, 2e-5],\n",
    "    \"weight_decay\": [0.0, 0.01],\n",
    "    \"batch_size\": [16, 32],\n",
    "    \"num_epochs\": [3]\n",
    "}\n",
    "\n",
    "# All combinations of hyperparameters\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "param_keys = list(param_grid.keys())\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "for param_set in param_combinations:\n",
    "    params = dict(zip(param_keys, param_set))\n",
    "    print(f\"Training with parameters: {params}\")\n",
    "\n",
    "    # Update dataloader if batch size changes\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=params[\"learning_rate\"], weight_decay=params[\"weight_decay\"])\n",
    "    num_training_steps = params[\"num_epochs\"] * len(train_dataloader)\n",
    "\n",
    "    lr_scheduler = get_scheduler(\n",
    "        name=\"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(params[\"num_epochs\"]):\n",
    "        model.train()\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss += outputs.loss.item()\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    accuracy = correct_predictions / len(val_dataset)\n",
    "\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}, Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "        print(\"New best model found!\")\n",
    "\n",
    "print(\"\\n=== Best Hyperparameters ===\")\n",
    "print(best_params)\n",
    "print(f\"Best Validation Accuracy: {best_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
