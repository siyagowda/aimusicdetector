{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ccc2c03-c1ba-46d6-95e0-dd2d316fd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b58b6d2c-c683-443c-a013-430d3ef1cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7995\n",
      "7995\n",
      "7995\n"
     ]
    }
   ],
   "source": [
    "# Load the predictions from CSV files\n",
    "\n",
    "mel_spec_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/mel-spec/mel-spec_test_large_with_aug_predictions.csv\"\n",
    "cqt_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/cqt/cqt_test_large_with_aug_predictions.csv\"\n",
    "mfcc_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/mfcc/mfcc_test_large_with_aug_predictions.csv\"\n",
    "plp_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/plp/plp_test_large_with_aug_predictions.csv\"\n",
    "chrm_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/chromagram/chromagram_test_large_with_aug_predictions.csv\"\n",
    "\n",
    "# Read the CSV files into pandas DataFrames\n",
    "df_mel = pd.read_csv(mel_spec_csv)\n",
    "df_mfcc = pd.read_csv(mfcc_csv)\n",
    "df_plp = pd.read_csv(plp_csv)\n",
    "df_cqt = pd.read_csv(cqt_csv)\n",
    "df_chrm = pd.read_csv(chrm_csv)\n",
    "\n",
    "print(len(df_mel.index))\n",
    "\n",
    "df_mel['base_filename'] = df_mel['filename'].str.replace(r'-Mel_Spectrogram\\.png$', '', regex=True)\n",
    "df_mfcc['base_filename'] = df_mfcc['filename'].str.replace(r'-MFCC\\.png$', '', regex=True)\n",
    "df_plp['base_filename'] = df_plp['filename'].str.replace(r'_plp\\.png$', '', regex=True)\n",
    "df_cqt['base_filename'] = df_cqt['filename'].str.replace(r'-CQT\\.png$', '', regex=True)\n",
    "df_chrm['base_filename'] = df_chrm['filename'].str.replace(r'-Chromagram\\.png$', '', regex=True)\n",
    "\n",
    "print(len(df_mel.index))\n",
    "print(len(df_plp.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e132f62-20aa-4bcc-a925-92f9eb511a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filename_mfcc', 'prob_ai_mfcc', 'prob_human_mfcc', 'true_label_mfcc',\n",
      "       'pred_label_mfcc', 'base_filename'],\n",
      "      dtype='object')\n",
      "Index(['filename_plp', 'prob_ai_plp', 'prob_human_plp', 'true_label_plp',\n",
      "       'pred_label_plp', 'base_filename'],\n",
      "      dtype='object')\n",
      "Index(['filename_cqt', 'prob_ai_cqt', 'prob_human_cqt', 'true_label_cqt',\n",
      "       'pred_label_cqt', 'base_filename'],\n",
      "      dtype='object')\n",
      "Index(['filename_chrm', 'prob_ai_chrm', 'prob_human_chrm', 'true_label_chrm',\n",
      "       'pred_label_chrm', 'base_filename'],\n",
      "      dtype='object')\n",
      "7995\n"
     ]
    }
   ],
   "source": [
    "def rename_columns(df, suffix):\n",
    "    return df.rename(columns={col: f\"{col}{suffix}\" for col in df.columns if col != 'base_filename'})\n",
    "\n",
    "# Add suffixes to avoid column name clashes\n",
    "df_mel = rename_columns(df_mel, '_mel')\n",
    "df_mfcc = rename_columns(df_mfcc, '_mfcc')\n",
    "df_plp = rename_columns(df_plp, '_plp')\n",
    "df_cqt = rename_columns(df_cqt, '_cqt')\n",
    "df_chrm = rename_columns(df_chrm, '_chrm')\n",
    "\n",
    "merged_df = df_mel.copy()\n",
    "# Merge sequentially on 'base_filename'\n",
    "for df in [df_mfcc, df_plp, df_cqt,  df_chrm]:\n",
    "    print(df.columns)  # Check before merge\n",
    "    assert 'base_filename' in df.columns\n",
    "    merged_df = pd.merge(merged_df, df, on='base_filename', how='left')\n",
    "\n",
    "#print(merged_df.head())\n",
    "print(len(merged_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb9e1283-0fb4-49dd-94d6-b0558c5dcd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AI probability columns\n",
    "human_prob_cols = [\n",
    "    'prob_human_mel',\n",
    "    'prob_human_mfcc',\n",
    "    'prob_human_plp',\n",
    "    'prob_human_cqt',\n",
    "    'prob_human_chrm'\n",
    "]\n",
    "\n",
    "missing_cols = [col for col in human_prob_cols if col not in merged_df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: Missing columns: {missing_cols}\")\n",
    "    # Filter to only existing columns\n",
    "    human_prob_cols = [col for col in human_prob_cols if col in merged_df.columns]\n",
    "    print(f\"Using available columns: {human_prob_cols}\")\n",
    "\n",
    "# Compute confidence = abs(prob_ai - 0.5)\n",
    "confidences = merged_df[human_prob_cols].apply(lambda x: np.abs(x - 0.5))\n",
    "\n",
    "# Get the column name of the highest-confidence prediction\n",
    "best_model_col = confidences.idxmax(axis=1)\n",
    "\n",
    "def get_best_prob(row):\n",
    "    best_col = confidences.loc[row.name].idxmax()\n",
    "    return row[best_col]\n",
    "\n",
    "merged_df['final_prob_ai_confidence_based'] = merged_df.apply(get_best_prob, axis=1)\n",
    "merged_df['final_pred_label_confidence_based'] = (merged_df['final_prob_ai_confidence_based'] >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b220b3f1-3ef6-430b-bae0-1b63359e9c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "Accuracy: 0.9710\n",
      "AUC: 0.9940\n",
      "\n",
      "Model selection frequency:\n",
      "prob_human_mel     4326\n",
      "prob_human_mfcc    2361\n",
      "prob_human_cqt     1205\n",
      "prob_human_chrm     101\n",
      "prob_human_plp        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_true = merged_df['true_label_mel']\n",
    "y_pred = merged_df['final_pred_label_confidence_based']\n",
    "\n",
    "# Calculate and display metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "auc = roc_auc_score(y_true, merged_df['final_prob_ai_confidence_based'])\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# Show distribution of which models were selected most often\n",
    "print(f\"\\nModel selection frequency:\")\n",
    "print(best_model_col.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "956cf388-d48d-424c-be6e-48e133dd4b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "Accuracy: 0.9710\n",
      "\n",
      "Metrics per class:\n",
      "\n",
      "Class: Human\n",
      "  Precision: 0.9747\n",
      "  Recall: 0.9706\n",
      "  F1: 0.9726\n",
      "  Accuracy: 0.9710\n",
      "  FPR: 0.0294\n",
      "\n",
      "Class: AI\n",
      "  Precision: 0.9668\n",
      "  Recall: 0.9715\n",
      "  F1: 0.9691\n",
      "  Accuracy: 0.9710\n",
      "  FPR: 0.0285\n"
     ]
    }
   ],
   "source": [
    "# Overall metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report (precision, recall, f1, support)\n",
    "#print(\"\\nClassification Report:\")\n",
    "#print(classification_report(y_true, y_pred, target_names=[\"Human\", \"AI\"]))\n",
    "\n",
    "# Confusion matrix and per-class metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "metrics_per_class = {\n",
    "    \"Human\": {\n",
    "        \"Precision\": tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        \"Recall\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"F1\": (2 * tn) / (2 * tn + fn + fp) if (2 * tn + fn + fp) > 0 else 0,\n",
    "        \"Accuracy\": (tn + tp) / (tn + fp + fn + tp),\n",
    "        \"FPR\": fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "    },\n",
    "    \"AI\": {\n",
    "        \"Precision\": tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        \"Recall\": tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        \"F1\": (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0,\n",
    "        \"Accuracy\": (tn + tp) / (tn + fp + fn + tp),\n",
    "        \"FPR\": fn / (fn + tp) if (fn + tp) > 0 else 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nMetrics per class:\")\n",
    "for label, metrics in metrics_per_class.items():\n",
    "    print(f\"\\nClass: {label}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27178958-35fb-45cc-86d9-93516285a283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
