{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ccc2c03-c1ba-46d6-95e0-dd2d316fd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b58b6d2c-c683-443c-a013-430d3ef1cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7995\n",
      "7995\n",
      "7995\n",
      "2967\n"
     ]
    }
   ],
   "source": [
    "# Load the predictions from CSV files\n",
    "\n",
    "mel_spec_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/mel-spec/mel-spec_test_large_with_aug_predictions.csv\"\n",
    "cqt_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/cqt/cqt_test_large_with_aug_predictions.csv\"\n",
    "mfcc_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/mfcc/mfcc_test_large_with_aug_predictions.csv\"\n",
    "plp_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/plp/plp_test_large_with_aug_predictions.csv\"\n",
    "chrm_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/music_cnn/large/chromagram/chromagram_test_large_with_aug_predictions.csv\"\n",
    "clean_lyrics_csv = \"/vol/bitbucket/sg2121/fyp/aimusicdetector/lyric_detection/large/clean_lyrics_test_large_predictions.csv\"\n",
    "\n",
    "# Read the CSV files into pandas DataFrames\n",
    "df_mel = pd.read_csv(mel_spec_csv)\n",
    "df_clean_lyrics = pd.read_csv(clean_lyrics_csv)\n",
    "df_mfcc = pd.read_csv(mfcc_csv)\n",
    "df_plp = pd.read_csv(plp_csv)\n",
    "df_cqt = pd.read_csv(cqt_csv)\n",
    "df_chrm = pd.read_csv(chrm_csv)\n",
    "\n",
    "print(len(df_mel.index))\n",
    "\n",
    "df_mel['base_filename'] = df_mel['filename'].str.replace(r'-Mel_Spectrogram\\.png$', '', regex=True)\n",
    "df_clean_lyrics['base_filename'] = df_clean_lyrics['filename'].str.replace(r'_lyrics\\.txt$', '', regex=True)\n",
    "df_mfcc['base_filename'] = df_mfcc['filename'].str.replace(r'-MFCC\\.png$', '', regex=True)\n",
    "df_plp['base_filename'] = df_plp['filename'].str.replace(r'_plp\\.png$', '', regex=True)\n",
    "df_cqt['base_filename'] = df_cqt['filename'].str.replace(r'-CQT\\.png$', '', regex=True)\n",
    "df_chrm['base_filename'] = df_chrm['filename'].str.replace(r'-Chromagram\\.png$', '', regex=True)\n",
    "\n",
    "print(len(df_mel.index))\n",
    "print(len(df_plp.index))\n",
    "print(len(df_clean_lyrics.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e132f62-20aa-4bcc-a925-92f9eb511a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filename_lyrics', 'prob_ai_lyrics', 'prob_human_lyrics',\n",
      "       'true_label_lyrics', 'pred_label_lyrics', 'base_filename'],\n",
      "      dtype='object')\n",
      "Index(['filename_mfcc', 'prob_ai_mfcc', 'prob_human_mfcc', 'true_label_mfcc',\n",
      "       'pred_label_mfcc', 'base_filename'],\n",
      "      dtype='object')\n",
      "Index(['filename_plp', 'prob_ai_plp', 'prob_human_plp', 'true_label_plp',\n",
      "       'pred_label_plp', 'base_filename'],\n",
      "      dtype='object')\n",
      "Index(['filename_cqt', 'prob_ai_cqt', 'prob_human_cqt', 'true_label_cqt',\n",
      "       'pred_label_cqt', 'base_filename'],\n",
      "      dtype='object')\n",
      "Index(['filename_chrm', 'prob_ai_chrm', 'prob_human_chrm', 'true_label_chrm',\n",
      "       'pred_label_chrm', 'base_filename'],\n",
      "      dtype='object')\n",
      "7995\n"
     ]
    }
   ],
   "source": [
    "def rename_columns(df, suffix):\n",
    "    return df.rename(columns={col: f\"{col}{suffix}\" for col in df.columns if col != 'base_filename'})\n",
    "\n",
    "# Add suffixes to avoid column name clashes\n",
    "df_mel = rename_columns(df_mel, '_mel')\n",
    "df_clean_lyrics = rename_columns(df_clean_lyrics, '_lyrics')\n",
    "df_mfcc = rename_columns(df_mfcc, '_mfcc')\n",
    "df_plp = rename_columns(df_plp, '_plp')\n",
    "df_cqt = rename_columns(df_cqt, '_cqt')\n",
    "df_chrm = rename_columns(df_chrm, '_chrm')\n",
    "\n",
    "merged_df = df_mel.copy()\n",
    "# Merge sequentially on 'base_filename'\n",
    "for df in [df_clean_lyrics, df_mfcc, df_plp, df_cqt,  df_chrm]:\n",
    "    print(df.columns)  # Check before merge\n",
    "    assert 'base_filename' in df.columns\n",
    "    merged_df = pd.merge(merged_df, df, on='base_filename', how='left')\n",
    "\n",
    "#print(merged_df.head())\n",
    "print(len(merged_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb9e1283-0fb4-49dd-94d6-b0558c5dcd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AI probability columns\n",
    "human_prob_cols = [\n",
    "    'prob_human_mel',\n",
    "    'prob_human_lyrics',\n",
    "    'prob_human_mfcc',\n",
    "    'prob_human_plp',\n",
    "    'prob_human_cqt',\n",
    "    'prob_human_chrm'\n",
    "]\n",
    "\n",
    "missing_cols = [col for col in human_prob_cols if col not in merged_df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: Missing columns: {missing_cols}\")\n",
    "    # Filter to only existing columns\n",
    "    human_prob_cols = [col for col in human_prob_cols if col in merged_df.columns]\n",
    "    print(f\"Using available columns: {human_prob_cols}\")\n",
    "\n",
    "# Compute confidence = abs(prob_ai - 0.5)\n",
    "confidences = merged_df[human_prob_cols].apply(lambda x: np.abs(x - 0.5))\n",
    "\n",
    "# Get the column name of the highest-confidence prediction\n",
    "best_model_col = confidences.idxmax(axis=1)\n",
    "\n",
    "def get_best_prob(row):\n",
    "    best_col = confidences.loc[row.name].idxmax()\n",
    "    return row[best_col]\n",
    "\n",
    "merged_df['final_prob_ai_confidence_based'] = merged_df.apply(get_best_prob, axis=1)\n",
    "merged_df['final_pred_label_confidence_based'] = (merged_df['final_prob_ai_confidence_based'] >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b220b3f1-3ef6-430b-bae0-1b63359e9c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "Accuracy: 0.9711\n",
      "AUC: 0.9940\n",
      "\n",
      "Model selection frequency:\n",
      "prob_human_mel       4325\n",
      "prob_human_mfcc      2360\n",
      "prob_human_cqt       1202\n",
      "prob_human_chrm       100\n",
      "prob_human_lyrics       6\n",
      "prob_human_plp          2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_true = merged_df['true_label_mel']\n",
    "y_pred = merged_df['final_pred_label_confidence_based']\n",
    "\n",
    "# Calculate and display metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "auc = roc_auc_score(y_true, merged_df['final_prob_ai_confidence_based'])\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# Show distribution of which models were selected most often\n",
    "print(f\"\\nModel selection frequency:\")\n",
    "print(best_model_col.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956cf388-d48d-424c-be6e-48e133dd4b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
